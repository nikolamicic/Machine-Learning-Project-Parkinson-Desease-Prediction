{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0beebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc27e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('parkinsons.data')  # Replace 'your_dataset.csv' with the actual file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf6ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = data.drop(['name', 'status'], axis=1)  # Remove 'name' column and keep all features except 'status'\n",
    "y = data['status']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30b5c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "# First, split the data into train_val and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.3, random_state=7,stratify=y)\n",
    "\n",
    "# Next, split the train_val set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=7,stratify=y_train_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb7e92f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31b81698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.90196</td>\n",
       "      <td>0.76471</td>\n",
       "      <td>0.82143</td>\n",
       "      <td>0.88462</td>\n",
       "      <td>0.62981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.91176</td>\n",
       "      <td>0.76471</td>\n",
       "      <td>0.82143</td>\n",
       "      <td>0.88462</td>\n",
       "      <td>0.62981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.95098</td>\n",
       "      <td>0.73529</td>\n",
       "      <td>0.81481</td>\n",
       "      <td>0.84615</td>\n",
       "      <td>0.61058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.89216</td>\n",
       "      <td>0.70588</td>\n",
       "      <td>0.76667</td>\n",
       "      <td>0.88462</td>\n",
       "      <td>0.50481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.95098</td>\n",
       "      <td>0.70588</td>\n",
       "      <td>0.78571</td>\n",
       "      <td>0.84615</td>\n",
       "      <td>0.54808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.89216</td>\n",
       "      <td>0.70588</td>\n",
       "      <td>0.76667</td>\n",
       "      <td>0.88462</td>\n",
       "      <td>0.50481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.88235</td>\n",
       "      <td>0.70588</td>\n",
       "      <td>0.76667</td>\n",
       "      <td>0.88462</td>\n",
       "      <td>0.50481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.89216</td>\n",
       "      <td>0.70588</td>\n",
       "      <td>0.76667</td>\n",
       "      <td>0.88462</td>\n",
       "      <td>0.50481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.89216</td>\n",
       "      <td>0.70588</td>\n",
       "      <td>0.76667</td>\n",
       "      <td>0.88462</td>\n",
       "      <td>0.50481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.88235</td>\n",
       "      <td>0.70588</td>\n",
       "      <td>0.76667</td>\n",
       "      <td>0.88462</td>\n",
       "      <td>0.50481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.89216</td>\n",
       "      <td>0.70588</td>\n",
       "      <td>0.76667</td>\n",
       "      <td>0.88462</td>\n",
       "      <td>0.50481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Train Accuracy  Validation Accuracy  Precision   Recall      AUC\n",
       "6          0.90196              0.76471    0.82143  0.88462  0.62981\n",
       "8          0.91176              0.76471    0.82143  0.88462  0.62981\n",
       "4          0.95098              0.73529    0.81481  0.84615  0.61058\n",
       "0          0.89216              0.70588    0.76667  0.88462  0.50481\n",
       "1          0.95098              0.70588    0.78571  0.84615  0.54808\n",
       "2          0.89216              0.70588    0.76667  0.88462  0.50481\n",
       "3          0.88235              0.70588    0.76667  0.88462  0.50481\n",
       "5          0.89216              0.70588    0.76667  0.88462  0.50481\n",
       "7          0.89216              0.70588    0.76667  0.88462  0.50481\n",
       "9          0.88235              0.70588    0.76667  0.88462  0.50481\n",
       "10         0.89216              0.70588    0.76667  0.88462  0.50481"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = [\n",
    "      LogisticRegression(solver='lbfgs',penalty='l2',max_iter=1000),\n",
    "      LogisticRegression(solver='lbfgs',penalty=None,max_iter=1000),\n",
    "      LogisticRegression(solver='liblinear',penalty='l1',max_iter=1000),\n",
    "      LogisticRegression(solver='liblinear',penalty='l2',max_iter=1000),\n",
    "      LogisticRegression(solver='newton-cg',penalty=None,max_iter=1000),\n",
    "      LogisticRegression(solver='newton-cg',penalty='l2',max_iter=1000),\n",
    "      LogisticRegression(solver='sag',penalty=None,max_iter=1000),\n",
    "      LogisticRegression(solver='sag',penalty='l2',max_iter=1000),\n",
    "      LogisticRegression(solver='saga',penalty=None,max_iter=1000),\n",
    "      LogisticRegression(solver='saga',penalty='l1',max_iter=1000),\n",
    "      LogisticRegression(solver='saga',penalty='l2',max_iter=1000),\n",
    "#     LogisticRegression(solver='sag',penalty=None),\n",
    "#     LogisticRegression(solver='saga',penalty=None)\n",
    "    ]\n",
    "clf_columns = []\n",
    "clf_compare = pd.DataFrame(columns = clf_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in clf:\n",
    "        \n",
    "    predicted = alg.fit(X_train, y_train).predict(X_val)\n",
    "    fp, tp, th = roc_curve(y_val, predicted)\n",
    "    clf_name = alg.__class__.__name__\n",
    "    clf_compare.loc[row_index, 'Train Accuracy'] = round(alg.score(X_train, y_train), 5)\n",
    "    clf_compare.loc[row_index, 'Validation Accuracy'] = round(alg.score(X_val, y_val), 5)\n",
    "    clf_compare.loc[row_index, 'Precision'] = round(precision_score(y_val, predicted),5)\n",
    "    clf_compare.loc[row_index, 'Recall'] = round(recall_score(y_val, predicted),5)\n",
    "    clf_compare.loc[row_index, 'AUC'] = round(auc(fp, tp),5)\n",
    "\n",
    "    row_index+=1\n",
    "    \n",
    "clf_compare.sort_values(by = ['Validation Accuracy'], ascending = False, inplace = True)    \n",
    "clf_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9343db7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad5dfc7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Print the best hyperparameters\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mbest_params\u001b[49m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest estimator:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best estimator:\", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f9fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model coef_\n",
    "best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(data.keys())\n",
    "print(N)\n",
    "print(list(data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation of intercept and coef values\n",
    "N = len(list(X.keys()))\n",
    "values = best_model.coef_[0]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(np.arange(0, N), values)\n",
    "plt.xticks(np.arange(0, N), list(X.keys()), rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee9778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eda70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy_lbfgs = accuracy_score(y_test, y_pred)\n",
    "precision_score_lbfgs = precision_score(y_test, y_pred)\n",
    "recall_score_lbfgs = recall_score(y_test, y_pred)\n",
    "f1_score_lbfgs = f1_score(y_test, y_pred)\n",
    "conf_matrix_lbfgs = confusion_matrix(y_test, y_pred)\n",
    "class_report_lbfgs = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_lbfgs:.2f}\")\n",
    "print(f\"Precision score: {precision_score_lbfgs:.2f}\")\n",
    "print(f\"Recall score: {recall_score_lbfgs:.2f}\")\n",
    "print(f\"F1 score: {f1_score_lbfgs:.2f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_lbfgs)\n",
    "print(\"Classification Report:\\n\", class_report_lbfgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901b783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'liblinear'good for very binary classification and high-dimensional datasets with a small number of samples. \n",
    "\n",
    "model_liblinear = LogisticRegression(solver='liblinear')\n",
    "model_liblinear.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93532522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model intercept_\n",
    "model_liblinear.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model coef_\n",
    "model_liblinear.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627803b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation of intercept and coef values for liblinear solver\n",
    "N = len(list(X.keys()))\n",
    "values = model_liblinear.coef_[0]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(np.arange(0, N), values)\n",
    "plt.xticks(np.arange(0, N), list(X.keys()), rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model_liblinear.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271f7f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model for liblinear solver\n",
    "accuracy_liblinear = accuracy_score(y_test, y_pred)\n",
    "precision_score_liblinear = precision_score(y_test, y_pred)\n",
    "recall_score_liblinear = recall_score(y_test, y_pred)\n",
    "f1_score_liblinear = f1_score(y_test, y_pred)\n",
    "conf_matrix_liblinear = confusion_matrix(y_test, y_pred)\n",
    "class_report_liblinear = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_liblinear:.2f}\")\n",
    "print(f\"Precision score: {precision_score_liblinear:.2f}\")\n",
    "print(f\"Recall score: {recall_score_liblinear:.2f}\")\n",
    "print(f\"F1 score: {f1_score_liblinear:.2f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_liblinear)\n",
    "print(\"Classification Report:\\n\", class_report_liblinear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be2010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import pickle\n",
    "\n",
    "with open('../models/log_reg_lbfgs_classifier.model.pickle', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "    \n",
    "with open('../models/log_reg_lbfgs_classifier.scaler.pickle', 'wb') as model_file:\n",
    "    pickle.dump(scaler, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1fac2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
